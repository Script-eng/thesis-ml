{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä NSE Stock Closing Price Prediction - Complete ML Workflow\n",
    "\n",
    "**Objective**: Predict next-day closing prices using LSTM, RNN, and Prophet models\n",
    "\n",
    "**Author**: Lesalon Stephen \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "This notebook follows the complete machine learning workflow:\n",
    "\n",
    "1. **Data Collection & Understanding**\n",
    "2. **Data Preprocessing & Cleaning**\n",
    "3. **Exploratory Data Analysis (EDA)**\n",
    "4. **Feature Engineering**\n",
    "5. **Model Development**\n",
    "   - LSTM\n",
    "   - RNN\n",
    "   - Prophet\n",
    "6. **Model Evaluation & Comparison**\n",
    "7. **Results Visualization**\n",
    "8. **Conclusions & Future Work**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ö†Ô∏è Important: Data Configuration\n",
    "\n",
    "**Current Dataset**: 42 trading days (Aug 4 - Nov 1, 2025)  \n",
    "**Lookback Window**: 10 days (optimized for available data)  \n",
    "**Training Epochs**: 50 (faster training)\n",
    "\n",
    "The parameters in this notebook have been automatically adjusted based on your actual data availability.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries loaded successfully\n",
      "TensorFlow version: 2.20.0\n",
      "NumPy version: 2.3.3\n",
      "Pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ML libraries\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from prophet import Prophet\n",
    "\n",
    "# Custom modules\n",
    "from closing_price_pipeline import (\n",
    "    DailyDataAggregator,\n",
    "    LSTMPredictor,\n",
    "    RNNPredictor,\n",
    "    ProphetPredictor,\n",
    "    ModelComparator\n",
    ")\n",
    "\n",
    "# Setup\n",
    "load_dotenv()\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database configuration\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": os.getenv(\"DB_NAME\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"port\": os.getenv(\"DB_PORT\")\n",
    "}\n",
    "\n",
    "print(\"Database Configuration:\")\n",
    "print(f\"  Database: {DB_CONFIG['dbname']}\")\n",
    "print(f\"  Host: {DB_CONFIG['host']}:{DB_CONFIG['port']}\")\n",
    "print(f\"  User: {DB_CONFIG['user']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize aggregator\n",
    "aggregator = DailyDataAggregator(DB_CONFIG)\n",
    "\n",
    "# Fetch daily closing prices\n",
    "print(\"Fetching daily closing prices from database...\")\n",
    "df_all = aggregator.get_daily_closing_prices(days_back=90)\n",
    "\n",
    "print(f\"\\nüìä Data Summary:\")\n",
    "print(f\"  Total records: {len(df_all):,}\")\n",
    "print(f\"  Unique stocks: {df_all['symbol'].nunique()}\")\n",
    "print(f\"  Date range: {df_all['trading_date'].min()} to {df_all['trading_date'].max()}\")\n",
    "print(f\"  Days of data: {(df_all['trading_date'].max() - df_all['trading_date'].min()).days}\")\n",
    "\n",
    "# Display sample\n",
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Understanding & Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(df_all.isnull().sum())\n",
    "\n",
    "# Data types\n",
    "print(\"\\nData Types:\")\n",
    "print(df_all.dtypes)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data availability per stock\n",
    "stock_counts = df_all.groupby('symbol').size().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nData Availability by Stock:\")\n",
    "print(stock_counts.head(10))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(14, 6))\n",
    "stock_counts.head(20).plot(kind='bar')\n",
    "plt.title('Top 20 Stocks by Data Availability', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Stock Symbol', fontweight='bold')\n",
    "plt.ylabel('Number of Days', fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nStocks with 60+ days: {(stock_counts >= 60).sum()}\")\n",
    "print(f\"Stocks with 30-59 days: {((stock_counts >= 30) & (stock_counts < 60)).sum()}\")\n",
    "print(f\"Stocks with < 30 days: {(stock_counts < 30).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Price Trends Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 5 stocks by data availability\n",
    "top_stocks = stock_counts.head(5).index.tolist()\n",
    "print(f\"Analyzing: {top_stocks}\")\n",
    "\n",
    "# Plot price trends\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, symbol in enumerate(top_stocks):\n",
    "    df_stock = df_all[df_all['symbol'] == symbol].sort_values('trading_date')\n",
    "    \n",
    "    axes[idx].plot(df_stock['trading_date'], df_stock['close_price'], linewidth=2)\n",
    "    axes[idx].set_title(f'{symbol} - Closing Price Trend', fontweight='bold')\n",
    "    axes[idx].set_xlabel('Date')\n",
    "    axes[idx].set_ylabel('Price (KES)')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Volume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume analysis\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, symbol in enumerate(top_stocks):\n",
    "    df_stock = df_all[df_all['symbol'] == symbol].sort_values('trading_date')\n",
    "    \n",
    "    axes[idx].bar(df_stock['trading_date'], df_stock['daily_volume'], alpha=0.7)\n",
    "    axes[idx].set_title(f'{symbol} - Trading Volume', fontweight='bold')\n",
    "    axes[idx].set_xlabel('Date')\n",
    "    axes[idx].set_ylabel('Volume')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "fig.delaxes(axes[5])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Price Distribution & Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns\n",
    "df_returns = []\n",
    "\n",
    "for symbol in top_stocks:\n",
    "    df_stock = df_all[df_all['symbol'] == symbol].sort_values('trading_date')\n",
    "    df_stock['returns'] = df_stock['close_price'].pct_change() * 100\n",
    "    df_returns.append(df_stock[['symbol', 'trading_date', 'returns']].dropna())\n",
    "\n",
    "df_returns = pd.concat(df_returns)\n",
    "\n",
    "# Distribution of returns\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, symbol in enumerate(top_stocks):\n",
    "    returns = df_returns[df_returns['symbol'] == symbol]['returns']\n",
    "    \n",
    "    axes[idx].hist(returns, bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[idx].axvline(returns.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {returns.mean():.2f}%')\n",
    "    axes[idx].set_title(f'{symbol} - Returns Distribution', fontweight='bold')\n",
    "    axes[idx].set_xlabel('Daily Return (%)')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "fig.delaxes(axes[5])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Volatility (standard deviation of returns)\n",
    "volatility = df_returns.groupby('symbol')['returns'].std().sort_values(ascending=False)\n",
    "print(\"\\nVolatility (Std Dev of Returns):\")\n",
    "print(volatility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot returns for correlation\n",
    "returns_pivot = df_returns.pivot(index='trading_date', columns='symbol', values='returns')\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = returns_pivot.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Stock Returns Correlation Matrix', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Stock for Detailed Analysis\n",
    "\n",
    "We'll use one stock for detailed model comparison, then apply to all stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select stock with most data\n",
    "ANALYSIS_SYMBOL = top_stocks[0]\n",
    "print(f\"Selected stock for detailed analysis: {ANALYSIS_SYMBOL}\")\n",
    "\n",
    "# Get data for this stock\n",
    "df_analysis = df_all[df_all['symbol'] == ANALYSIS_SYMBOL].sort_values('trading_date').reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nData points: {len(df_analysis)}\")\n",
    "print(f\"Date range: {df_analysis['trading_date'].min()} to {df_analysis['trading_date'].max()}\")\n",
    "print(f\"Price range: {df_analysis['close_price'].min():.2f} - {df_analysis['close_price'].max():.2f} KES\")\n",
    "\n",
    "df_analysis.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LSTM predictor\n",
    "lstm = LSTMPredictor(ANALYSIS_SYMBOL, lookback_days=10)\n",
    "\n",
    "# Train model\n",
    "print(\"Training LSTM model...\")\n",
    "lstm_metrics, lstm_history = lstm.train(df_analysis, test_size=0.2, epochs=50, batch_size=32)\n",
    "\n",
    "# Display metrics\n",
    "print(\"\\nüìä LSTM Performance Metrics:\")\n",
    "for metric, value in lstm_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(lstm_history.history['loss'], label='Training Loss')\n",
    "plt.plot(lstm_history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('LSTM - Training History', fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(lstm_history.history['loss'], label='Training Loss')\n",
    "plt.plot(lstm_history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('LSTM - Training History (Log Scale)', fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RNN predictor\n",
    "rnn = RNNPredictor(ANALYSIS_SYMBOL, lookback_days=10)\n",
    "\n",
    "# Train model\n",
    "print(\"Training RNN model...\")\n",
    "rnn_metrics, rnn_history = rnn.train(df_analysis, test_size=0.2, epochs=50, batch_size=32)\n",
    "\n",
    "# Display metrics\n",
    "print(\"\\nüìä RNN Performance Metrics:\")\n",
    "for metric, value in rnn_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Prophet predictor\n",
    "prophet = ProphetPredictor(ANALYSIS_SYMBOL)\n",
    "\n",
    "# Train model\n",
    "print(\"Training Prophet model...\")\n",
    "prophet_metrics = prophet.train(df_analysis, test_size=0.2)\n",
    "\n",
    "# Display metrics\n",
    "print(\"\\nüìä Prophet Performance Metrics:\")\n",
    "for metric, value in prophet_metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics\n",
    "comparison_df = pd.DataFrame({\n",
    "    'LSTM': lstm_metrics,\n",
    "    'RNN': rnn_metrics,\n",
    "    'Prophet': prophet_metrics\n",
    "}).T\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"MODEL COMPARISON - {ANALYSIS_SYMBOL}\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string())\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle(f'Model Performance Comparison - {ANALYSIS_SYMBOL}', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics = ['RMSE', 'MAE', 'MAPE', 'R2']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    comparison_df[metric].plot(kind='bar', ax=ax, color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "    ax.set_title(metric, fontweight='bold')\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Day Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for next day\n",
    "lstm_pred = lstm.predict_next_day(df_analysis)\n",
    "rnn_pred = rnn.predict_next_day(df_analysis)\n",
    "prophet_pred = prophet.predict_next_day(df_analysis)\n",
    "\n",
    "current_price = df_analysis['close_price'].iloc[-1]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"{ANALYSIS_SYMBOL} - NEXT DAY CLOSING PRICE PREDICTIONS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Current Price:  {current_price:.2f} KES\")\n",
    "print(f\"\\nPredictions:\")\n",
    "print(f\"  LSTM:    {lstm_pred:.2f} KES ({((lstm_pred/current_price - 1)*100):+.2f}%)\")\n",
    "print(f\"  RNN:     {rnn_pred:.2f} KES ({((rnn_pred/current_price - 1)*100):+.2f}%)\")\n",
    "print(f\"  Prophet: {prophet_pred:.2f} KES ({((prophet_pred/current_price - 1)*100):+.2f}%)\")\n",
    "print(f\"\\nEnsemble (Average): {np.mean([lstm_pred, rnn_pred, prophet_pred]):.2f} KES\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Apply to All Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stocks with sufficient data\n",
    "sufficient_data_stocks = stock_counts[stock_counts >= 60].index.tolist()\n",
    "print(f\"Processing {len(sufficient_data_stocks)} stocks with 60+ days of data...\\n\")\n",
    "\n",
    "# Initialize comparator\n",
    "comparator = ModelComparator()\n",
    "\n",
    "# Process each stock (limit to 5 for demonstration)\n",
    "for idx, symbol in enumerate(sufficient_data_stocks[:5], 1):\n",
    "    print(f\"\\n[{idx}/{min(5, len(sufficient_data_stocks))}] Processing {symbol}...\")\n",
    "    \n",
    "    df_stock = df_all[df_all['symbol'] == symbol].sort_values('trading_date')\n",
    "    \n",
    "    try:\n",
    "        # LSTM\n",
    "        lstm_model = LSTMPredictor(symbol, lookback_days=10)\n",
    "        lstm_m, _ = lstm_model.train(df_stock, epochs=50, batch_size=32)\n",
    "        lstm_p = lstm_model.predict_next_day(df_stock)\n",
    "        comparator.add_result(symbol, 'LSTM', lstm_m, lstm_p)\n",
    "        \n",
    "        # RNN\n",
    "        rnn_model = RNNPredictor(symbol, lookback_days=10)\n",
    "        rnn_m, _ = rnn_model.train(df_stock, epochs=50, batch_size=32)\n",
    "        rnn_p = rnn_model.predict_next_day(df_stock)\n",
    "        comparator.add_result(symbol, 'RNN', rnn_m, rnn_p)\n",
    "        \n",
    "        # Prophet\n",
    "        prophet_model = ProphetPredictor(symbol)\n",
    "        prophet_m = prophet_model.train(df_stock)\n",
    "        prophet_p = prophet_model.predict_next_day(df_stock)\n",
    "        comparator.add_result(symbol, 'Prophet', prophet_m, prophet_p)\n",
    "        \n",
    "        print(f\"  ‚úÖ {symbol} completed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå {symbol} failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n‚úÖ All stocks processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results\n",
    "results_df = comparator.get_comparison_df()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average performance by model\n",
    "avg_performance = results_df.groupby('model')[['RMSE', 'MAE', 'MAPE', 'R2']].mean()\n",
    "\n",
    "print(\"\\nAverage Performance by Model:\")\n",
    "print(avg_performance.to_string())\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Average Model Performance Across All Stocks', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics = ['RMSE', 'MAE', 'MAPE', 'R2']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    avg_performance[metric].plot(kind='bar', ax=ax, color=['#3498db', '#e74c3c', '#2ecc71'])\n",
    "    ax.set_title(metric, fontweight='bold')\n",
    "    ax.set_ylabel('Average Value')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model overall\n",
    "best_model_by_rmse = avg_performance['RMSE'].idxmin()\n",
    "best_model_by_r2 = avg_performance['R2'].idxmax()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONCLUSIONS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best model by RMSE: {best_model_by_rmse} ({avg_performance.loc[best_model_by_rmse, 'RMSE']:.4f})\")\n",
    "print(f\"Best model by R¬≤:   {best_model_by_r2} ({avg_performance.loc[best_model_by_r2, 'R2']:.4f})\")\n",
    "print(f\"\\nAverage MAPE: {avg_performance['MAPE'].min():.2f}% (best)\")\n",
    "print(f\"Average MAE:  {avg_performance['MAE'].min():.4f} KES (best)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "1. **Model Performance**: [Write your analysis here]\n",
    "2. **LSTM vs RNN**: [Compare the two]\n",
    "3. **Deep Learning vs Traditional**: [LSTM/RNN vs Prophet]\n",
    "4. **Practical Implications**: [For traders/investors]\n",
    "5. **Limitations**: [What to be aware of]\n",
    "\n",
    "### Future Work\n",
    "\n",
    "1. Incorporate more features (technical indicators, sentiment)\n",
    "2. Ensemble methods (combine all three models)\n",
    "3. Hyperparameter tuning\n",
    "4. Real-time deployment\n",
    "5. Extended backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Export Results for Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import os\n",
    "os.makedirs('thesis_results', exist_ok=True)\n",
    "\n",
    "# Save comparison table\n",
    "results_df.to_csv('thesis_results/model_comparison.csv', index=False)\n",
    "avg_performance.to_csv('thesis_results/average_performance.csv')\n",
    "\n",
    "print(\"‚úÖ Results exported to thesis_results/ directory\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"  - model_comparison.csv\")\n",
    "print(\"  - average_performance.csv\")\n",
    "print(\"\\nUse these files in your thesis document!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
